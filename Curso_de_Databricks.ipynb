{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoG3aRHr3MT92DKRrZtcPa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seldoncode/tutorial/blob/main/Curso_de_Databricks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Curso de Databricks**\n",
        "## **√çndice**\n",
        "\n",
        "### **M√≥dulo 1: Introducci√≥n y Conceptos Fundamentales**\n",
        "1. **Tema 1: Introducci√≥n a Databricks**\n",
        "   - 1.1 ¬øQu√© es Databricks y por qu√© es importante?\n",
        "   - 1.2 Arquitectura Lakehouse y sus ventajas\n",
        "   - 1.3 Casos de uso: Data Engineering, Data Science, Analytics, ML\n",
        "   - 1.4 Ecosistema: Relaci√≥n con Apache Spark y la nube\n",
        "\n",
        "2. **Tema 2: Fundamentos de Apache Spark**\n",
        "   - 2.1 ¬øQu√© es Apache Spark y procesamiento distribuido?\n",
        "   - 2.2 RDDs, DataFrames y Datasets\n",
        "   - 2.3 Transformaciones vs Acciones (lazy evaluation)\n",
        "   - 2.4 Spark UI b√°sico para monitoreo\n",
        "\n",
        "### **M√≥dulo 2: Primeros Pasos Pr√°cticos**\n",
        "3. **Tema 3: Configuraci√≥n del Entorno**\n",
        "   - 3.1 Creaci√≥n de cuenta (Community Edition o trial)\n",
        "   - 3.2 Tour por la interfaz: Workspace, Data, Compute, Workflows\n",
        "   - 3.3 Creaci√≥n del primer cluster\n",
        "   - 3.4 Configuraci√≥n b√°sica de clusters (autoscaling, autotermination)\n",
        "\n",
        "4. **Tema 4: Introducci√≥n a Notebooks**\n",
        "   - 4.1 Creaci√≥n y ejecuci√≥n de notebooks\n",
        "   - 4.2 Lenguajes disponibles y cambio entre ellos\n",
        "   - 4.3 Magic commands (%python, %sql, %fs, %sh)\n",
        "   - 4.4 Widgets para parametrizaci√≥n\n",
        "\n",
        "### **M√≥dulo 3: Trabajando con Datos**\n",
        "5. **Tema 5: Gesti√≥n de Datos en Databricks**\n",
        "   - 5.1 DBFS (Databricks File System) y rutas\n",
        "   - 5.2 Carga de datos desde m√∫ltiples fuentes (CSV, JSON, Parquet)\n",
        "   - 5.3 **Introducci√≥n a Delta Lake: ventajas y caracter√≠sticas**\n",
        "   - 5.4 Cat√°logo de datos y tablas (managed vs external)\n",
        "\n",
        "6. **Tema 6: Manipulaci√≥n de Datos con PySpark**\n",
        "   - 6.1 Creaci√≥n de DataFrames\n",
        "   - 6.2 Operaciones b√°sicas: select, filter, withColumn\n",
        "   - 6.3 Transformaciones comunes: groupBy, join, orderBy\n",
        "   - 6.4 Manejo de valores nulos y duplicados\n",
        "\n",
        "7. **Tema 7: SQL en Databricks**\n",
        "   - 7.1 SQL en notebooks\n",
        "   - 7.2 Creaci√≥n de tablas y vistas\n",
        "   - 7.3 Consultas SQL b√°sicas y avanzadas\n",
        "   - 7.4 **SQL Warehouses (introducci√≥n b√°sica)**\n",
        "\n",
        "### **M√≥dulo 4: Delta Lake (Fundamental para Databricks)**\n",
        "8. **Tema 8: Trabajando con Delta Lake**\n",
        "   - 8.1 Creaci√≥n de tablas Delta\n",
        "   - 8.2 ACID transactions en la pr√°ctica\n",
        "   - 8.3 Time Travel y versionado\n",
        "   - 8.4 Operaciones MERGE, UPDATE, DELETE\n",
        "\n",
        "### **M√≥dulo 5: An√°lisis y Visualizaci√≥n**\n",
        "9. **Tema 9: An√°lisis de Datos**\n",
        "   - 9.1 Agregaciones y estad√≠sticas descriptivas\n",
        "   - 9.2 Window functions\n",
        "   - 9.3 **User Defined Functions (UDF) - b√°sico**\n",
        "\n",
        "10. **Tema 10: Visualizaci√≥n**\n",
        "    - 10.1 Visualizaciones nativas en notebooks\n",
        "    - 10.2 Dashboards b√°sicos\n",
        "    - 10.3 Integraci√≥n con herramientas externas (opcional)\n",
        "\n",
        "### **M√≥dulo 6: Workflows y Automatizaci√≥n**\n",
        "11. **Tema 11: Jobs y Workflows**\n",
        "    - 11.1 ¬øQu√© son los Jobs en Databricks?\n",
        "    - 11.2 Creaci√≥n de un Job b√°sico\n",
        "    - 11.3 Programaci√≥n y triggers\n",
        "    - 11.4 Monitoreo de ejecuciones\n",
        "\n",
        "### **M√≥dulo 7: Buenas Pr√°cticas y Gesti√≥n**\n",
        "12. **Tema 12: Control de Versiones**\n",
        "    - 12.1 Integraci√≥n con Git (Repos)\n",
        "    - 12.2 Workflows de desarrollo (dev/prod)\n",
        "    - 12.3 Organizaci√≥n del workspace\n",
        "\n",
        "13. **Tema 13: Optimizaci√≥n y Mejores Pr√°cticas**\n",
        "    - 13.1 Gesti√≥n eficiente de clusters y costos\n",
        "    - 13.2 Particionamiento de datos\n",
        "    - 13.3 Optimizaci√≥n de Delta (OPTIMIZE, Z-ORDER)\n",
        "    - 13.4 Debugging y Spark UI avanzado\n",
        "\n",
        "### **M√≥dulo 8: Proyecto Final**\n",
        "14. **Tema 14: Proyecto Integrador**\n",
        "    - 14.1 ETL completo: ingesta ‚Üí transformaci√≥n ‚Üí almacenamiento\n",
        "    - 14.2 An√°lisis y visualizaci√≥n\n",
        "    - 14.3 Automatizaci√≥n con Jobs\n",
        "    - 14.4 Documentaci√≥n y presentaci√≥n\n",
        "\n",
        "### **Recursos y Pr√≥ximos Pasos**\n",
        "15. **Tema 15: Continuando el Aprendizaje**\n",
        "    - 15.1 Certificaciones Databricks\n",
        "    - 15.2 Temas avanzados sugeridos\n",
        "    - 15.3 Comunidad y recursos\n",
        "\n",
        "---\n",
        "\n",
        "### Duraci√≥n estimada\n",
        "- 8 semanas\n",
        "\n",
        "### ¬øQu√© aprender√°s en este curso?\n",
        "\n",
        "Este curso te guiar√° desde cero en el mundo de **Databricks**, la plataforma l√≠der para anal√≠tica de datos a gran escala. Al finalizar, ser√°s capaz de:\n",
        "\n",
        "- Comprender qu√© es Databricks y c√≥mo se integra en el ecosistema moderno de datos\n",
        "- Trabajar con Apache Spark de forma pr√°ctica\n",
        "- Procesar y analizar grandes vol√∫menes de datos\n",
        "- Crear pipelines de datos automatizados\n",
        "- Aplicar buenas pr√°cticas en ingenier√≠a de datos\n",
        "\n",
        "### Metodolog√≠a del Curso\n",
        "\n",
        "Este curso est√° dise√±ado con un enfoque **100% pr√°ctico**:\n",
        "\n",
        "- **Teor√≠a m√≠nima necesaria**: Solo los conceptos esenciales\n",
        "- **Ejercicios hands-on**: Cada concepto se practica inmediatamente\n",
        "- **Ejemplos del mundo real**: Casos de uso aplicables a tu trabajo\n",
        "- **Proyecto integrador**: Construcci√≥n de un pipeline completo de datos\n",
        "\n",
        "### Requisitos Previos\n",
        "\n",
        "Para aprovechar al m√°ximo este curso, necesitas:\n",
        "\n",
        "1. **Conocimientos b√°sicos de Python** (variables, funciones, estructuras de control)\n",
        "2. **Familiaridad con SQL** (SELECT, WHERE, JOIN b√°sicos)\n",
        "3. **Conceptos b√°sicos de bases de datos** (qu√© es una tabla, registro, columna)\n",
        "4. **Acceso a internet** para usar Databricks Community Edition\n",
        "\n",
        "> üí° **Nota**: Si no tienes experiencia con Python o SQL, no te preocupes. Iremos paso a paso y los conceptos se explican de forma clara.\n",
        "\n",
        "### Estructura de los Apuntes\n",
        "\n",
        "Estos apuntes siguen una estructura consistente:\n",
        "- üìö **Teor√≠a**: Conceptos fundamentales explicados de forma clara\n",
        "- üíª **Pr√°ctica**: C√≥digo ejecutable que puedes probar\n",
        "- ‚ö†Ô∏è **Importante**: Puntos cr√≠ticos a recordar\n",
        "- üí° **Tip**: Consejos y mejores pr√°cticas\n",
        "- üéØ **Ejercicio**: Retos para practicar lo aprendido\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YYbcVWVpOEd7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **M√≥dulo 1: Introducci√≥n y Conceptos Fundamentales**\n",
        "\n",
        "---\n",
        "\n",
        "## **Tema 1: Introducci√≥n a Databricks**\n",
        "\n",
        "### **1.1 ¬øQu√© es Databricks y por qu√© es importante?**\n",
        "\n",
        "#### **¬øQu√© es Databricks?**\n",
        "\n",
        "**Databricks** es una plataforma unificada de anal√≠tica de datos construida sobre **Apache Spark**. Fue fundada en 2013 por los creadores originales de Apache Spark (en la Universidad de Berkeley).\n",
        "\n",
        "Piensa en Databricks como un **entorno de trabajo completo** que te permite:\n",
        "\n",
        "- **Procesar** grandes cantidades de datos (desde megabytes hasta petabytes)\n",
        "- **Colaborar** con tu equipo en tiempo real (como Google Docs, pero para datos)\n",
        "- **Automatizar** pipelines de datos complejos\n",
        "- **Analizar** datos con SQL, Python, Scala o R\n",
        "- **Entrenar** modelos de Machine Learning a escala\n",
        "- **Orquestar** workflows de principio a fin\n",
        "\n",
        "#### **Analog√≠a para entenderlo mejor**\n",
        "\n",
        "Imagina que eres un chef:\n",
        "\n",
        "- **Excel/Python local** = Tu cocina casera (buenos para platos peque√±os)\n",
        "- **Databricks** = Una cocina industrial profesional (dise√±ada para vol√∫menes grandes, equipos, y eficiencia)\n",
        "\n",
        "As√≠ como una cocina industrial tiene equipos especializados, procesos optimizados y permite que varios chefs trabajen simult√°neamente, Databricks hace lo mismo con tus datos.\n",
        "\n",
        "#### **¬øPor qu√© es importante Databricks?**\n",
        "\n",
        "##### **1. Resuelve problemas del mundo real**\n",
        "\n",
        "Cuando trabajas con datos en 2025, te enfrentas a:\n",
        "\n",
        "```python\n",
        "# Problema 1: VOLUMEN - Datos demasiado grandes\n",
        "# Tu laptop tiene 16GB RAM, pero tus datos pesan 500GB\n",
        "# ‚ùå Pandas no puede cargar todo en memoria\n",
        "# ‚úÖ Databricks distribuye el procesamiento en m√∫ltiples m√°quinas\n",
        "\n",
        "# Problema 2: VELOCIDAD - Procesamiento lento\n",
        "# Un an√°lisis en tu laptop tarda 8 horas\n",
        "# ‚ùå No puedes esperar tanto para tomar decisiones\n",
        "# ‚úÖ Databricks lo procesa en minutos usando procesamiento paralelo\n",
        "\n",
        "# Problema 3: COLABORACI√ìN - Trabajo aislado\n",
        "# Tu c√≥digo funciona en tu m√°quina, pero no en la de tu colega\n",
        "# ‚ùå \"En mi m√°quina funciona\"\n",
        "# ‚úÖ Databricks provee un entorno compartido y consistente\n",
        "```\n",
        "\n",
        "##### **2. Unifica el ciclo completo de datos**\n",
        "\n",
        "Antes de Databricks, necesitabas m√∫ltiples herramientas:\n",
        "\n",
        "```\n",
        "Ingesta de datos     ‚Üí  Herramienta A\n",
        "Transformaci√≥n       ‚Üí  Herramienta B  \n",
        "An√°lisis             ‚Üí  Herramienta C\n",
        "Machine Learning     ‚Üí  Herramienta D\n",
        "Orquestaci√≥n         ‚Üí  Herramienta E\n",
        "Visualizaci√≥n        ‚Üí  Herramienta F\n",
        "```\n",
        "\n",
        "Con Databricks, todo est√° en un solo lugar:\n",
        "\n",
        "```\n",
        "Databricks Lakehouse Platform\n",
        "‚îú‚îÄ‚îÄ Ingesta de datos\n",
        "‚îú‚îÄ‚îÄ Transformaci√≥n (ETL/ELT)\n",
        "‚îú‚îÄ‚îÄ Almacenamiento (Delta Lake)\n",
        "‚îú‚îÄ‚îÄ An√°lisis SQL\n",
        "‚îú‚îÄ‚îÄ Machine Learning\n",
        "‚îú‚îÄ‚îÄ Orquestaci√≥n (Jobs/Workflows)\n",
        "‚îî‚îÄ‚îÄ Dashboards\n",
        "```\n",
        "\n",
        "##### **3. Construido sobre Apache Spark**\n",
        "\n",
        "Apache Spark es el motor de procesamiento distribuido m√°s usado en el mundo para Big Data. Databricks te da acceso a Spark sin la complejidad de configurarlo y mantenerlo.\n",
        "\n",
        "```python\n",
        "# Sin Databricks: Configurar Spark localmente\n",
        "# - Instalar Java\n",
        "# - Instalar Scala\n",
        "# - Configurar SPARK_HOME\n",
        "# - Gestionar dependencias\n",
        "# - Configurar cluster\n",
        "# - Mantener versiones...\n",
        "# ‚è±Ô∏è Puede tomar d√≠as\n",
        "\n",
        "# Con Databricks:\n",
        "# 1. Crear cuenta\n",
        "# 2. Crear cluster (3 clics)\n",
        "# 3. Empezar a trabajar\n",
        "# ‚è±Ô∏è 5 minutos\n",
        "```\n",
        "\n",
        "#### **Casos de uso reales**\n",
        "\n",
        "##### **Ejemplo 1: E-commerce**\n",
        "\n",
        "```python\n",
        "\"\"\"\n",
        "Problema: Una tienda online tiene millones de transacciones diarias\n",
        "y necesita an√°lisis en tiempo real.\n",
        "\n",
        "Con Databricks:\n",
        "1. Ingesta de logs de servidor (streaming)\n",
        "2. Procesamiento de eventos de compra en tiempo real\n",
        "3. Detecci√≥n de fraude usando ML\n",
        "4. Dashboards para el equipo de negocio\n",
        "5. Recomendaciones personalizadas\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "##### **Ejemplo 2: Salud**\n",
        "\n",
        "```python\n",
        "\"\"\"\n",
        "Problema: Un hospital necesita analizar historiales m√©dicos de\n",
        "millones de pacientes para investigaci√≥n.\n",
        "\n",
        "Con Databricks:\n",
        "1. Unificaci√≥n de datos de m√∫ltiples sistemas\n",
        "2. Anonimizaci√≥n de datos sensibles\n",
        "3. An√°lisis estad√≠stico a gran escala\n",
        "4. Modelos predictivos para diagn√≥sticos\n",
        "5. Cumplimiento normativo (HIPAA, GDPR)\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "##### **Ejemplo 3: Finanzas**\n",
        "\n",
        "```python\n",
        "\"\"\"\n",
        "Problema: Un banco procesa millones de transacciones y necesita\n",
        "detectar actividades sospechosas.\n",
        "\n",
        "Con Databricks:\n",
        "1. Ingesta de transacciones en tiempo real\n",
        "2. An√°lisis de patrones hist√≥ricos\n",
        "3. Modelos de detecci√≥n de anomal√≠as\n",
        "4. Reportes regulatorios automatizados\n",
        "5. Data governance y auditor√≠a\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "#### **¬øQui√©n usa Databricks?**\n",
        "\n",
        "Empresas de todos los tama√±os y sectores:\n",
        "\n",
        "- **Tecnolog√≠a**: Comcast, Shell, H&M\n",
        "- **Finanzas**: ING, HSBC, Capital One\n",
        "- **Retail**: Walgreens, Cond√© Nast\n",
        "- **Salud**: Regeneron Pharmaceuticals\n",
        "- **Media**: Fox, NBC Universal\n",
        "\n",
        "#### **Ventajas clave de Databricks**\n",
        "\n",
        "```python\n",
        "# 1. ESCALABILIDAD\n",
        "# Procesa desde KB hasta PB sin cambiar tu c√≥digo\n",
        "df = spark.read.parquet(\"data.parquet\")  # Funciona igual con 1GB o 1TB\n",
        "\n",
        "# 2. VELOCIDAD\n",
        "# Procesamiento distribuido y en memoria\n",
        "# Lo que tarda horas en Pandas, puede tomar minutos\n",
        "\n",
        "# 3. COLABORACI√ìN\n",
        "# Notebooks compartidos en tiempo real\n",
        "# Control de versiones integrado\n",
        "\n",
        "# 4. MULTI-LENGUAJE\n",
        "# Python, SQL, Scala, R en el mismo notebook\n",
        "\n",
        "# 5. GESTI√ìN AUTOMATIZADA\n",
        "# Clusters que se crean/destruyen autom√°ticamente\n",
        "# Optimizaci√≥n de costos\n",
        "\n",
        "# 6. SEGURIDAD Y GOVERNANCE\n",
        "# Control de acceso granular\n",
        "# Auditor√≠a completa\n",
        "# Cumplimiento normativo\n",
        "```\n",
        "\n",
        "#### **Ecosistema Databricks**\n",
        "\n",
        "Databricks no trabaja solo, se integra con:\n",
        "\n",
        "```\n",
        "‚òÅÔ∏è Clouds:\n",
        "   - AWS (Amazon Web Services)\n",
        "   - Azure (Microsoft)\n",
        "   - GCP (Google Cloud Platform)\n",
        "\n",
        "üìä Almacenamiento:\n",
        "   - S3, Azure Blob, Google Cloud Storage\n",
        "   - Delta Lake (formato optimizado)\n",
        "\n",
        "üîß Herramientas:\n",
        "   - Power BI, Tableau (visualizaci√≥n)\n",
        "   - dbt (transformaci√≥n)\n",
        "   - Airflow (orquestaci√≥n)\n",
        "   - MLflow (ML lifecycle)\n",
        "\n",
        "üîå Conectores:\n",
        "   - Bases de datos (MySQL, PostgreSQL, SQL Server)\n",
        "   - Data warehouses (Snowflake, Redshift)\n",
        "   - APIs y servicios web\n",
        "```\n",
        "\n",
        "#### **Databricks vs Otras Herramientas**\n",
        "\n",
        "```python\n",
        "\"\"\"\n",
        "DATABRICKS vs PANDAS\n",
        "--------------------\n",
        "Pandas: Excelente para datasets peque√±os (<5GB) en una sola m√°quina\n",
        "Databricks: Dise√±ado para datasets grandes, procesamiento distribuido\n",
        "\n",
        "DATABRICKS vs SNOWFLAKE\n",
        "-----------------------\n",
        "Snowflake: Data warehouse optimizado para SQL\n",
        "Databricks: Plataforma completa (SQL + Python + ML + Streaming)\n",
        "\n",
        "DATABRICKS vs AWS EMR\n",
        "---------------------\n",
        "EMR: Infraestructura Spark en AWS (m√°s control, m√°s complejidad)\n",
        "Databricks: Plataforma gestionada (menos administraci√≥n, m√°s productividad)\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üíª **Pr√°ctica Inicial - Comprendiendo el Concepto**\n",
        "\n",
        "Antes de instalar nada, vamos a simular el problema que Databricks resuelve:\n",
        "\n",
        "```python\n",
        "# Celda de Python en tu Jupyter Notebook\n",
        "\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Simulemos procesar un dataset \"grande\" con Pandas\n",
        "print(\"üêº Procesamiento con Pandas (simulaci√≥n)\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Crear un dataset de ejemplo\n",
        "data = {\n",
        "    'cliente_id': range(1000000),\n",
        "    'compra': [100 + i % 500 for i in range(1000000)],\n",
        "    'categoria': ['A', 'B', 'C'] * 333334\n",
        "}\n",
        "\n",
        "# Medir tiempo\n",
        "inicio = time.time()\n",
        "df_pandas = pd.DataFrame(data)\n",
        "resultado = df_pandas.groupby('categoria')['compra'].sum()\n",
        "fin = time.time()\n",
        "\n",
        "print(f\"‚úÖ Tiempo de procesamiento: {fin - inicio:.4f} segundos\")\n",
        "print(f\"üìä Resultado:\\n{resultado}\")\n",
        "print(\"\\n‚ö†Ô∏è Limitaci√≥n: Pandas requiere que TODO quepa en memoria\")\n",
        "print(\"‚ö†Ô∏è Con 10M, 100M o 1B de filas... tu laptop colapsar√≠a\")\n",
        "```\n",
        "\n",
        "**Salida esperada:**\n",
        "```\n",
        "üêº Procesamiento con Pandas (simulaci√≥n)\n",
        "--------------------------------------------------\n",
        "‚úÖ Tiempo de procesamiento: 0.1234 segundos\n",
        "üìä Resultado:\n",
        "categoria\n",
        "A    166583350000\n",
        "B    166583350000\n",
        "C    166666650000\n",
        "Name: compra, dtype: int64\n",
        "\n",
        "‚ö†Ô∏è Limitaci√≥n: Pandas requiere que TODO quepa en memoria\n",
        "‚ö†Ô∏è Con 10M, 100M o 1B de filas... tu laptop colapsar√≠a\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ **Ejercicio 1.1 - Reflexi√≥n**\n",
        "\n",
        "Antes de continuar, responde en una celda Markdown:\n",
        "\n",
        "```markdown\n",
        "### Reflexi√≥n Personal\n",
        "\n",
        "1. **¬øQu√© tipo de datos manejo actualmente en mi trabajo/estudios?**\n",
        "   - Volumen aproximado:\n",
        "   - Formato (CSV, Excel, JSON, etc.):\n",
        "   - Frecuencia de actualizaci√≥n:\n",
        "\n",
        "2. **¬øQu√© problemas enfrento con mis herramientas actuales?**\n",
        "   - [ ] Lentitud en el procesamiento\n",
        "   - [ ] Datos demasiado grandes para mi m√°quina\n",
        "   - [ ] Dificultad para compartir an√°lisis\n",
        "   - [ ] Falta de automatizaci√≥n\n",
        "   - [ ] Otro: _______________\n",
        "\n",
        "3. **¬øC√≥mo podr√≠a Databricks ayudarme?**\n",
        "   (Tu respuesta aqu√≠)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ö†Ô∏è **Puntos Clave para Recordar**\n",
        "\n",
        "```markdown\n",
        "1. **Databricks = Plataforma unificada** para todo el ciclo de vida de datos\n",
        "2. **Construida sobre Apache Spark** (procesamiento distribuido)\n",
        "3. **Resuelve problemas de escala** que herramientas tradicionales no pueden\n",
        "4. **Colaborativa y cloud-native** desde el dise√±o\n",
        "5. **Multi-prop√≥sito**: Data Engineering, Data Science, Analytics, ML\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üí° **Tips Profesionales**\n",
        "\n",
        "```markdown\n",
        "‚úÖ Databricks no reemplaza Excel o Pandas para an√°lisis peque√±os\n",
        "   ‚Üí √ösalo cuando el volumen o la complejidad lo justifique\n",
        "\n",
        "‚úÖ La curva de aprendizaje vale la pena\n",
        "   ‚Üí Es una habilidad muy demandada en el mercado laboral\n",
        "\n",
        "‚úÖ Empieza con Community Edition (gratis)\n",
        "   ‚Üí Practica sin costos antes de usar versiones empresariales\n",
        "\n",
        "‚úÖ Databricks es el futuro del an√°lisis de datos\n",
        "   ‚Üí Grandes empresas est√°n migrando a arquitecturas Lakehouse\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üìö **Recursos Adicionales**\n",
        "\n",
        "```markdown\n",
        "üìñ Documentaci√≥n oficial: https://docs.databricks.com\n",
        "üéì Databricks Academy (cursos gratuitos): https://www.databricks.com/learn\n",
        "üì∫ Canal de YouTube: Databricks\n",
        "üê¶ Twitter: @databricks\n",
        "üí¨ Community Forums: https://community.databricks.com\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **Pr√≥ximos Pasos**\n",
        "\n",
        "En la siguiente secci√≥n (1.2), profundizaremos en la **Arquitectura Lakehouse** y entenderemos c√≥mo Databricks organiza y procesa los datos de forma eficiente.\n",
        "\n",
        "---\n",
        "\n",
        "### üìù **Notas Personales**\n",
        "\n",
        "```markdown\n",
        "<!-- Usa este espacio para tus propias anotaciones -->\n",
        "\n",
        "Fecha: _______________\n",
        "Dudas:\n",
        "-\n",
        "-\n",
        "\n",
        "Conceptos a reforzar:\n",
        "-\n",
        "-\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "¬øListo para continuar con el punto 1.2? ¬°Av√≠same cuando quieras seguir avanzando!"
      ],
      "metadata": {
        "id": "7CFtVf2_O6C4"
      }
    }
  ]
}